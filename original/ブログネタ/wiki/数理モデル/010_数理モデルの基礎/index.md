---
title: '数理モデルの基礎'
description: '数理モデルの基礎'
date: '2025-01-03'
categories: []
weight: 10
math: true
---

```mermaid
flowchart LR
    A[generative models]--->B[discriminative models]
    B--->C[discriminant functions]
```

\\( p (t\, x) \\) があれば \\( p (t | x) \\) を導出することは可能であり、\\( p(t|x) \\) に対して \\( y := f(x) := \int t \\,\\, dp(t|x) \\) を導出することも可能。

このことからもわかる通り、\\( p(t\, x) > \\) の順でモデルを生成することが難しいことがわかる。

また、機械学習タスクが上記のどれを求めているかを意識しておくと理解の整理が進むかもしれない。

## ベイズ統計



## あ

真の確率分布を \\( \mathbb{P} (X) \\)  とします。 \\( \mathbb{P} (X) \\) が求まれば万々歳ですが、「実際のデータが発生するメカニズムは複雑であり正確に求めるのは困難であること」、「実現したい内容によっては \\( \mathbb{P} (X) \\) 自体を求める必要がないこと」から、単純、かつ、目的に適った数理モデルを定式化して解く方が現実的でしょう。

真の確率分布 \\( \mathbb{P} (X) \\) から \\( N \\) 個の i.i.d (independent and identically distributed; 独立同分布) なデータ \\( X _ {1}\, \dots\, X _ {N} \\) が得られている状況のもとで、
最初に「単純かつ目的に適った数理モデルを設定」し、次に「設定した数理モデルに対して、得られたデータ \\( (X _ {i}) \\) に最適なパラメータを推定」することになります。

ここで最適なパラメータとはどのようなものになるでしょうか。
ここである種の近さの概念が必要になります。

\\( X _ {i} = (x _ {i}\, y _ {i}) \\) となるデータ群であり、\\( y = f (x)\\) となる関数 \\( f \\) を求めることが目的である場合、数理モデルとして第一に考えるべきは discriminant functions でしょう。
数値を予測する機械学習タスクのほとんどがこの数理モデルを採用しています。
この場合、\\( \mathbb{E} (\ell (f(x | w)\, y)) := \int (\int \ell (f(x | w)\, y) d \mathbb{P} (y|x) ) d \mathbb{P} (x)\\)



説明する数理モデルを求めることが大目的となります。

とはいえ、データが潤沢なケースでなかったりデータを表現するための数理モデルがないケースがあるため、問題設定に応じてどの models や functions を説明するモデルを作成したいのかを決める必要があります。

generative models や discriminative といった確率モデルを求めたい場合は最尤推定法を用いるか、真の分布との





## 推定量

| 確率モデルの解釈 | ハイパーパラメータ 1 点を推定 | 分布を推定 |
| ---------------- | ----------------------------- | ---------- |
| 頻度主義統計     | 最尤推定                      |            |
| ベイズ統計       | MAP 推定                      | ベイズ推定 |
|                  |                               |            |



- 最尤推定量
- 

