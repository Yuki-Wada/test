---
title: '情報量基準'
description: '情報量基準'
date: '2025-01-03'
categories: []
weight: 60
math: true
---





|            | 計算にパラメータの最尤推定値が必要                           | 計算にベイズ推定が必要                                       |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 汎化誤差   | AIC（赤池情報量基準）<br/>TIC（最尤推定量 \\( \hat{\theta} \\) の汎化誤差） | DIC（事後平均 \\( \bar{\theta} \\) の汎化誤差）<br />WAIC（\\( \theta \\) の事後分布の汎化誤差） |
| エビデンス | BIC                                                          | WBIC                                                         |

MDL、Cross-validation？



## 思ったこと

結論から言えば、AIC は

- データ数 \\( n \\) が十分大きい（\\( n \rightarrow \infty \\)）
- 推測に用いる分布で真のモデルが実現できる

という条件の下で

- 最尤推定量の平均対数尤度（≒汎化誤差）

の推定量を計算した値となります。

「条件の制約が厳しかったこと」、「計算して得られる推定量が平均対数尤度の最小値ではなく、最尤推定に対する平均対数尤度であること」が個人的には意外でした。

適切な条件のもとで \\( n \rightarrow \infty \\) のときに最尤推定量 \\( \hat{\theta} \\) が \\( \theta _ {0} \\) に収束することは知られていますが、もしデータが潤沢にあるならば、「パラメータの最尤推定に使うデータ（≒学習データ）」と「平均対数尤度を計算に使うデータ（≒検証用データ）」に分けてしまった方が、AIC を計算するよりも、直感的かつ直接的に平均対数尤度を計算できそうだという感想を抱き６７６５６５ました。

とはいえ、以下の観点から AIC が機械学習に与えた影響は大きいとも思いました。

- 平均対数尤度の推定量というコンセプトは現代でもそのまま生き残っていること
- 「手元のデータに対する最尤推定量をそのまま使うと過学習が発生してしまう」という現象を「モデルパラメータが多すぎる」という明快な理由で説明したこと
- 過学習を抑制するための判定基準が、データから計算できる平均対数尤度にパラメータ数を足すという簡単な計算によって得られたこと

平均対数尤度を最小にするパラメータを求めることは機械学習において重要です。

- 最尤推定に対する平均対数尤度ではなく、最適値に対する平均対数尤度を推定できないか
- 平均対数尤度を推定するだけではなく、平均対数尤度を小さくする勾配を計算することができないか

正則化項を付け加えることによっても過学習を防ぐことができますが、これはパラメータの増大条件にキャップをかけることで過学習を防いでいるのであって、平均対数尤度と結び付けるにはギャップがあるように見えます。



## 最尤推定量 \\( \hat{\theta} \\) の平均対数尤度に関する情報量基準

AIC 

- AIC（Akaike's Information Criterion、赤池情報量基準）
- c-AIC
- TIC（Takeuchi Information Criterion、竹内情報量基準）
- GIC（Generalized Information Criterion、一般化情報量基準）
- EIC（Extended Information Criterion）

**（問題設定）**

- 真の分布の確率密度関数を \\( g (x) \\)、推測に用いるパラメトリックな分布を \\( f (x | \theta) \\)とする。

- 真の分布から得られた \\( n \\) 個のデータを \\( \mathbf{X} := (X _ {i}) _ {i = 1 \dots n} \\) とする。
- 標本対数尤度を以下で定義する。

\\[ \\begin{aligned}  L(\\theta; \\mathbf{X}): =  \\sum _ {i = 1}^{n} \\log f (X _ {i} | \\theta)  \\end{aligned} \\]

- 平均対数尤度を以下で定義する。

\\[ \\begin{aligned}  E(\\theta) := \\mathbb{E} (X|\\theta)  \\end{aligned} \\]

（※）モデルパラメータの最適化の観点では、標本対数尤度を訓練誤差、平均対数尤度を汎化誤差と呼ぶことが多い。

（※）平均対数尤度は定数だが、標本対数尤度は \\( \mathbf{X} \\) に依存しているため確率変数である。



**（推定量）**

- 標本対数尤度 \\( L(\theta; X) \\) を最小にする \\( \hat{\theta} \\) を最尤推定量という。\\( \hat{\theta} \\) は \\( \mathbf{X} \\) に依存するため確率変数である。
- 平均対数尤度 \\( E(\theta) \\) を最小にする \\( \theta _ {0} \\) を最適値と呼ぶこととする。


\\[ \\begin{aligned}  b(g) = L (\\hat{\\theta}) - n \\mathbb{E} (X|\\theta _ {0})  \\end{aligned} \\]



このタイプの情報量基準では、以下の値を最小化することを基本方針とする。
\\[ \\begin{align} -2 n \\mathbb{E} (f (Z | \\hat{\\theta} )) = & -2 \\left( \\sum _ {i = 1}^{n} \\log p (X _ {i} | \\hat{\\theta}) + b(g) \\right) \\\\ \\end{align} \\]
\\( b(g) \\) をどのように推定するかによって、
\\[ \\begin{align} b(g) = & \\underbrace{ \\left( \\log f (X _ {n} |̂ \\hat{\\theta}(X _ {n})) − \\log f (X _ {n}|\\theta _ {0}) \\right) } _ {D _ {1}} \\\\ + & \\underbrace{ \\left( \\log f (X _ {n}|\\theta _ {0}) − n \\mathbb{E} _ {Z} \\left( \\log f (Z|\\theta _ {0}) \\right) \\right)} _ {D _ {2}} \\\\ + & \\underbrace{ n \\mathbb{E} _ {Z} \\left(\\log f (Z|\\theta _ {0}) − \\log f (Z|̂\\hat{\\theta}(X _ {n})) \\right)} _ {D _ {3}} \\end{align} \\]
\\( D _ {1} \\) はサンプルデータに対する最尤推定量と真値のズレ \\( > 0 \\)、\\( D _ {2} \\) は汎化誤差のサンプルによる推定量、\\( D _ {3} \\) は真の分布に対する真値と最尤推定量のズレ \\( > 0 \\) を表している。




#### AIC・TIC の導出

\\( b(g) \\) の推定値として、\\( \mathbb{E} _ {\mathbf{X}} (b(g)) \\) を





最終的に \\( \mathbb{E} (b(g)) \xrightarrow[n \rightarrow \infty]{p} \text{tr} \left( I(\theta _ {0}) J(\theta _ {0})^{-1} \right) \\) であることがわかる。  この結果を用いて、TIC を以下の式で定義する。
\\[ \\begin{aligned}  TIC := -2 \\left( L(\\hat{\\theta}; \\mathbf{X}) + \\text{tr} \\left( I (\\hat{\\theta}) J (\\hat{\\theta})^{-1} \\right) \\right).  \\end{aligned} \\]
AIC では、さらに真のモデルが \\( g (x) = f (x | \theta _ {0}) \\) と書けることを仮定する。

このとき、\\(  I (\theta) = J (\theta) \\) となることから、\\( f \\) が持つパラメータの個数を \\( p \\) として、\\( \text{tr} \left( I (\hat{\theta}) J (\hat{\theta})^{-1} \right) = \text{tr} \left( I _ {p} \right) = p \\) であることがわかる。この結果を用いて、AIC を以下の式で定義する。
\\[ \\begin{aligned}  AIC := -2 \\left( L(\\hat{\\theta}; \\mathbf{X}) + p \\right)  \\end{aligned} \\]















